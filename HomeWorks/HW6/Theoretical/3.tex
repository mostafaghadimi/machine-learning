\سؤال{درخت تصمیم}

\begin{itemize}
	\item الف)
	$$
	Gain(y, x_d) = \Sigma_{i}\Sigma_{j} p(y=j, x_d=i) log \frac{p(x_d=i)p(y=j)}{p(y=j, x_d=i)}
	$$
	با توجه به استقلال $y$ و $x_d$ داریم:
	$$
	p(y, x_d) = p(y)p(x_d)
	$$
	$$
	\implies Gain(y, x_d) = \Sigma_{i}\Sigma_{j} p(y=j, x_d=i) log \frac{p(x_d=i)p(y=j)}{p(y=j)p(x_d=i)}
	= \Sigma_{i}\Sigma_{j} p(y=j, x_d=i) log(1) = 0$$ 
	\item ب)
	اگر ملاک ساختن درخت تصمیم‌گیری را براساس مقدار \lr{information gain} قرار دهیم، به دلیل استقلال و یکتا بودن آن (همانند قسمت قبل)، مقدار \lr{gain} برابر با صفر می‌شود. پس به عنوان ریشه‌ی درخت قرار نمی‌گیرد. 
	
	حال اگر فرض کنیم این ویژگی به عنوان ریشه انتخاب شده، \lr{overfitting} به دلیل یکتایی ویژگی‌ها حتمی خواهد بود. برای جلوگیری از \lr{overfitting} عمدتا دو راه‌کار وجود دارد:
	\begin{enumerate}
		\item زودتر متوقف کردن درخت برای  این‌که به نقطه‌ای نرسد که همه‌ی داده‌های آموزش را به‌طور کامل و عالی یاد گرفته باشد.
		\item استفاده از تکنیک \lr{post-pruning}. به روی‌کردی می‌گویند که داده‌ی آموزش و اعتبارسنجی وجود دارد که برای هرس کردن از آن استفاده می‌شود.
	\end{enumerate}
	\item پ)
	\begin{itemize}
		\item یک)
		\item دو)
		\item سه)
	\end{itemize}
\end{itemize}